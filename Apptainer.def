Bootstrap: docker
From: rockylinux:8.8

%labels
    Author YourCompany
    CUDA torch-cu124
    Purpose gpt-oss-20b-lora-sft

%environment
    export LANG=C.UTF-8
    export LC_ALL=C.UTF-8
    export PYTHONUNBUFFERED=1
    export HF_HOME=/workspace/hf
    export TRANSFORMERS_CACHE=/workspace/hf
    export CUDA_VISIBLE_DEVICES=all

%post
    set -e

    echo "=== System packages ==="
    dnf install -y \
        python311 \
        python311-devel \
        git \
        gcc \
        gcc-c++ \
        make \
        wget \
        which \
        numactl-libs \
        epel-release \
        && dnf clean all

    # 啟用 PowerTools（部分依賴可能需要）
    dnf config-manager --set-enabled powertools

    ln -sf /usr/bin/python3.11 /usr/bin/python
    ln -sf /usr/bin/pip3.11 /usr/bin/pip

    echo "=== Upgrade pip ==="
    pip install --no-cache-dir --upgrade pip setuptools wheel \
        --trusted-host pypi.org \
        --trusted-host pypi.python.org \
        --trusted-host files.pythonhosted.org

    echo "=== Install PyTorch (CUDA 12.4 - latest) ==="
    pip install --no-cache-dir \
        torch torchvision torchaudio \
        --index-url https://download.pytorch.org/whl/cu124 \
        --trusted-host download.pytorch.org

    echo "=== Verify torch ==="
    python - << 'EOF'
import torch
print("torch:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
print("GPU name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No GPU")
EOF

    echo "=== Install LLM stack ==="
    pip install --no-cache-dir \
        transformers \
        datasets \
        accelerate \
        peft \
        trl \
        sentencepiece \
        protobuf \
        einops \
        --trusted-host pypi.org \
        --trusted-host pypi.python.org \
        --trusted-host files.pythonhosted.org

    echo "=== bitsandbytes ==="
    pip install --no-cache-dir bitsandbytes \
        --trusted-host pypi.org \
        --trusted-host pypi.python.org \
        --trusted-host files.pythonhosted.org

    echo "=== unsloth (latest from GitHub) ==="
    pip install --no-cache-dir "unsloth[cu124-torch260] @ git+https://github.com/unslothai/unsloth.git" \
        --trusted-host github.com

    echo "=== Sanity import test ==="
    python - << 'EOF'
import torch
from unsloth import FastLanguageModel
import transformers, trl, bitsandbytes, datasets, accelerate, peft
print("torch:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
print("GPU name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No GPU")
print("ALL IMPORT OK - Unsloth ready!")
EOF

%runscript
    exec python "$@"