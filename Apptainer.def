Bootstrap: docker
From: nvidia/cuda:12.4.0-base-rockylinux8

%environment
    export PATH=/opt/conda/bin:$PATH
    export LD_LIBRARY_PATH=/usr/local/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH
    export HF_HOME=/app/.cache/huggingface
    export TORCH_HOME=/app/.cache/torch
    export TRANSFORMERS_CACHE=/app/.cache/huggingface/transformers
    export HF_DATASETS_CACHE=/app/.cache/huggingface/datasets
    export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

%post
    # 設置時區和語言
    ln -sf /usr/share/zoneinfo/Asia/Taipei /etc/localtime
    
    # 安裝基礎依賴
    dnf update -y
    dnf install -y epel-release
    dnf install -y \
        wget \
        git \
        git-lfs \
        cmake \
        gcc \
        gcc-c++ \
        make \
        automake \
        autoconf \
        libtool \
        pkgconfig \
        python39 \
        python39-devel \
        python39-pip \
        openssl-devel \
        bzip2-devel \
        readline-devel \
        sqlite-devel \
        tk-devel \
        libffi-devel \
        xz-devel \
        zlib-devel \
        ncurses-devel \
        gmp-devel \
        mpfr-devel \
        libmpc-devel \
        mesa-libGL-devel \
        mesa-libEGL-devel \
        libcurl-devel \
        which
    
    # 安裝 Miniconda
    wget https://repo.anaconda.com/miniconda/Miniconda3-py39_24.1.2-0-Linux-x86_64.sh -O /tmp/miniconda.sh
    bash /tmp/miniconda.sh -b -p /opt/conda
    rm /tmp/miniconda.sh
    
    # 設置 conda 環境
    export PATH="/opt/conda/bin:$PATH"
    conda init
    conda update -y conda
    
    # 創建 Python 虛擬環境
    conda create -y -n gpt-oss python=3.9
    echo "source /opt/conda/bin/activate gpt-oss" >> $APPTAINER_ENVIRONMENT
    
    # 激活環境並安裝基礎包
    source /opt/conda/bin/activate gpt-oss
    pip install --upgrade pip
    pip install wheel setuptools
    
    # 安裝 PyTorch with CUDA 12.4
    pip install torch==2.8.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
    
    # 安裝 NVIDIA 相關庫
    pip install nvidia-cudnn-cu12==8.9.7.29 nvidia-cublas-cu12==12.4.5.117 nvidia-cufft-cu12==11.2.1.19 \
                nvidia-curand-cu12==10.3.5.119 nvidia-cusolver-cu12==11.6.1.18 nvidia-cusparse-cu12==12.3.1.19 \
                nvidia-nccl-cu12==2.20.5 nvidia-cuda-nvrtc-cu12==12.4.127 nvidia-cuda-runtime-cu12==12.4.127 \
                nvidia-cuda-cupti-cu12==12.4.127 nvidia-cudnn-frontend-cu12==0.2.2 nvidia-cusolver-cu12==11.6.1.18
    
    # 安裝 Triton
    pip install triton==3.4.0
    
    # 安裝其他依賴
    pip install \
        numpy==1.26.4 \
        pillow==10.4.0 \
        transformers==4.56.2 \
        tokenizers==0.21.0 \
        datasets==3.2.0 \
        accelerate==1.3.1 \
        bitsandbytes==0.43.5 \
        peft==0.13.2 \
        trl==0.22.2 \
        scipy==1.13.1 \
        sentencepiece==0.2.0 \
        protobuf==5.29.0 \
        jinja2==3.1.4 \
        markupsafe==2.1.5
    
    # 安裝 Unsloth 和相關包
    pip install \
        "unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo" \
        "unsloth[base] @ git+https://github.com/unslothai/unsloth"
    
    # 創建應用目錄
    mkdir -p /app
    mkdir -p /app/.cache/huggingface
    mkdir -p /app/.cache/torch
    chmod -R 777 /app/.cache
    
    # 下載模型權重（可選，如果需要在容器中預載）
    # cd /app
    # git lfs install
    # git clone https://huggingface.co/unsloth/gpt-oss-20b

%runscript
    #!/bin/bash
    source /opt/conda/bin/activate gpt-oss
    exec python "$@"

%files
    # 這裡可以添加本地文件，例如：
    # requirements.txt /app/
    # model_weights/ /app/model_weights/

%labels
    Author "Your Name"
    Version "1.0"
    Description "GPT-OSS-20B Fine-tuning Environment for Offline Use"

%help
    This container provides an isolated environment for fine-tuning GPT-OSS-20B model.
    It includes:
    - Python 3.9 with Conda
    - PyTorch 2.8.0 with CUDA 12.4
    - Transformers, Datasets, PEFT, TRL
    - Unsloth for efficient fine-tuning
    
    To run fine-tuning:
    apptainer run gpt-oss-finetune.sif train_script.py
    
    To enter shell:
    apptainer shell gpt-oss-finetune.sif